---
title: Imputando datos. La estructura importa
author: ''
date: '2021-06-13'
slug: imputando-datos-la-estructura-importa
categories:
  - estadística
tags:
  - imputación
  - estadística
description: ''
topics: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>


<p>Voy a empezar este post con un par de citas.</p>
<blockquote>
<p><em>El análisis de datos es básicamente encontrar la matriz correcta a diagonalizar.</em></p>
</blockquote>
<blockquote>
<p><em>Quien renuncia a la estructura, deja dinero encima de la mesa.</em></p>
</blockquote>
<p>La primera no recuerdo dónde la leí, pero es de la escuela francesa de estadística, la segunda es del blog hermano <a href="https://www.datanalytics.com/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/">datanalytics</a>.</p>
<p>Y bueno, ambas tienen parte de razón. En esta entrada voy a comentar brevemente una forma de imputación de datos que quizá a alguien le sea útil.</p>
<p>La idea básica es:</p>
<ol style="list-style-type: decimal">
<li>Imputar los valores perdidos por la media de cada variable.</li>
<li>Calcular la estructura factorial con el dataset anterior.</li>
<li>Imputar los valores perdidos por los valores predichos por la estructura factorial. Usando la matriz X reconstruida.</li>
<li>Repetir hasta convergencia.</li>
</ol>
<p>Este procedimiento iterativo suele usar Expectation Maximization y se conoce como EM-PCA. (también hay versión usando regularización)</p>
<p>Más información en este <a href="http://www.numdam.org/item/JSFS_2012__153_2_79_0.pdf">artículo</a> de François Husson</p>
<div id="ejemplo" class="section level2">
<h2>Ejemplo</h2>
<p>Y ahora vamos a ver un ejemplito, para eso vamos a usar la librería <code>missMDA</code> de François Husson y Julie Josse, que incorpora estos métodos.</p>
<pre class="r"><code>library(missMDA)</code></pre>
<p>Usamos el conjunto de datos <code>orange</code> en cuya ayuda leeemos</p>
<p><em>Description</em>
Sensory description of 12 orange juices by 8 attributes. Some values are missing.</p>
<p><em>Usage</em>
data(orange)
<em>Format</em>
A data frame with 12 rows and 8 columns. Rows represent the different orange juices, columns represent the attributes.</p>
<pre class="r"><code>data(orange)</code></pre>
<p>Por ejemplo, tenemos un valor perdido para la variable <code>Attack.intensity</code> en la primera fila</p>
<pre class="r"><code>DT::datatable(orange,
               options = list(scrollX = TRUE))</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12"],[4.79166666666667,4.58333333333333,4.70833333333333,6.58333333333333,null,6.33333333333333,4.29166666666667,null,4.41666666666667,4.54166666666667,4.08333333333333,6.5],[5.29166666666667,6.04166666666667,5.33333333333333,6,6.16666666666667,5,4.91666666666667,4.54166666666667,null,4.29166666666667,5.125,5.875],[null,4.41666666666667,null,7.41666666666667,5.33333333333333,5.375,5.29166666666667,4.83333333333333,5.16666666666667,null,3.91666666666667,6.125],[null,5.45833333333333,null,4.16666666666667,4.08333333333333,5,5.54166666666667,null,4.625,5.79166666666667,null,4.875],[null,4.125,4.29166666666667,6.75,null,5.5,5.25,4.95833333333333,5.04166666666667,4.375,null,5.29166666666667],[2.83333333333333,3.54166666666667,3.16666666666667,null,4.375,3.625,null,2.91666666666667,3.66666666666667,null,null,4.16666666666667],[null,4.625,6.25,1.41666666666667,3.41666666666667,4.20833333333333,1.29166666666667,1.54166666666667,1.54166666666667,null,7.33333333333333,1.5],[5.20833333333333,4.45833333333333,5.16666666666667,3.41666666666667,4.41666666666667,4.875,4.33333333333333,3.95833333333333,3.95833333333333,5,5.25,3.5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Color.intensity<\/th>\n      <th>Odor.intensity<\/th>\n      <th>Attack.intensity<\/th>\n      <th>Sweet<\/th>\n      <th>Acid<\/th>\n      <th>Bitter<\/th>\n      <th>Pulp<\/th>\n      <th>Typicity<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Bien, pues ahora podemos usar el EM-PCA para imputar los valores perdidos teniendo en cuenta la estructura factorial. Usamos el ejemplo que viene en la función.</p>
<p>Estimamos el número de componentes a extraer y usamos la función <code>imputePCA</code> que</p>
<pre class="r"><code>estim_ncpPCA(orange)</code></pre>
<pre><code>## Warning in impute(X, ncp = ncp, scale = scale, method = method, ind.sup =
## ind.sup, : Stopped after 1000 iterations</code></pre>
<pre><code>## $ncp
## [1] 2
## 
## $criterion
##         0         1         2         3         4         5 
## 1.0388714 0.9279948 0.5976727 0.7855501 2.0250470 2.6741735</code></pre>
<pre class="r"><code>res_impute &lt;-  imputePCA(orange, ncp=2)</code></pre>
<p>La función devuelve el conjunto de datos ya imputado</p>
<pre class="r"><code>res_impute$completeObs</code></pre>
<pre><code>##    Color.intensity Odor.intensity Attack.intensity    Sweet     Acid   Bitter
## 1         4.791667       5.291667         4.077034 5.527352 4.177564 2.833333
## 2         4.583333       6.041667         4.416667 5.458333 4.125000 3.541667
## 3         4.708333       5.333333         4.158054 5.442936 4.291667 3.166667
## 4         6.583333       6.000000         7.416667 4.166667 6.750000 4.702509
## 5         6.271605       6.166667         5.333333 4.083333 5.455805 4.375000
## 6         6.333333       5.000000         5.375000 5.000000 5.500000 3.625000
## 7         4.291667       4.916667         5.291667 5.541667 5.250000 3.214232
## 8         4.460613       4.541667         4.833333 5.479128 4.958333 2.916667
## 9         4.416667       5.136550         5.166667 4.625000 5.041667 3.666667
## 10        4.541667       4.291667         4.176991 5.791667 4.375000 2.735255
## 11        4.083333       5.125000         3.916667 5.703297 3.900164 2.815857
## 12        6.500000       5.875000         6.125000 4.875000 5.291667 4.166667
##        Pulp Typicity
## 1  5.711715 5.208333
## 2  4.625000 4.458333
## 3  6.250000 5.166667
## 4  1.416667 3.416667
## 5  3.416667 4.416667
## 6  4.208333 4.875000
## 7  1.291667 4.333333
## 8  1.541667 3.958333
## 9  1.541667 3.958333
## 10 4.026062 5.000000
## 11 7.333333 5.250000
## 12 1.500000 3.500000</code></pre>
</div>
<div id="extensiones" class="section level2">
<h2>Extensiones</h2>
<p>Se puede hacer imputación múltiple.</p>
<pre class="r"><code># creamos 100 datasets imputados, 
# por defecto usa método bootstrap pero también puede usar una versión bayesiana
res_mi_impute &lt;- MIPCA(orange, ncp = 2, nboot = 100)</code></pre>
<p>En el Slot <code>res.MI</code> tenemos los datasets imputados</p>
<pre class="r"><code># vemos por ejemplo la imputación 3
res_mi_impute$res.MI[[3]]</code></pre>
<pre><code>##    Color.intensity Odor.intensity Attack.intensity    Sweet     Acid   Bitter
## 1         4.791667       5.291667         3.954364 5.879781 4.656048 2.833333
## 2         4.583333       6.041667         4.416667 5.458333 4.125000 3.541667
## 3         4.708333       5.333333         4.333241 6.212547 4.291667 3.166667
## 4         6.583333       6.000000         7.416667 4.166667 6.750000 4.963685
## 5         5.513219       6.166667         5.333333 4.083333 5.867583 4.375000
## 6         6.333333       5.000000         5.375000 5.000000 5.500000 3.625000
## 7         4.291667       4.916667         5.291667 5.541667 5.250000 2.782590
## 8         4.741117       4.541667         4.833333 4.519020 4.958333 2.916667
## 9         4.416667       5.030443         5.166667 4.625000 5.041667 3.666667
## 10        4.541667       4.291667         4.282674 5.791667 4.375000 2.442581
## 11        4.083333       5.125000         3.916667 6.010708 3.530739 2.929682
## 12        6.500000       5.875000         6.125000 4.875000 5.291667 4.166667
##        Pulp Typicity
## 1  8.327411 5.208333
## 2  4.625000 4.458333
## 3  6.250000 5.166667
## 4  1.416667 3.416667
## 5  3.416667 4.416667
## 6  4.208333 4.875000
## 7  1.291667 4.333333
## 8  1.541667 3.958333
## 9  1.541667 3.958333
## 10 5.029165 5.000000
## 11 7.333333 5.250000
## 12 1.500000 3.500000</code></pre>
<p>Cuando el conjunto de datos es pequeño, como en este caso (12 filas), podemos ver gráficamente la incertidumbre asociada a la imputación. En la ayuda de la función <code>plot.MIPCA</code> se puede consultar lo que significa cada gráfico</p>
<pre class="r"><code>plot(res_mi_impute)</code></pre>
<p><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-1.png" width="672" /><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-2.png" width="672" /><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-3.png" width="672" /><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-4.png" width="672" /></p>
<pre><code>## $PlotIndProc</code></pre>
<p><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-5.png" width="672" /></p>
<pre><code>## 
## $PlotDim</code></pre>
<p><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-6.png" width="672" /></p>
<pre><code>## 
## $PlotIndSupp</code></pre>
<p><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-7.png" width="672" /></p>
<pre><code>## 
## $PlotVar</code></pre>
<p><img src="/post/2021-06-13-imputando-datos-la-estructura-importa_files/figure-html/unnamed-chunk-9-8.png" width="672" /></p>
</div>
<div id="mas-extensiones" class="section level2">
<h2>Mas extensiones</h2>
<p>La librería que subyace bajo <code>missMDA</code> es la conocida <code>FactoMineR</code> que permite hacer métodos factoriales (otros nombres para lo mismo serían métodos de componentes principales, reducción de dimensiones, projection pursuit) teniendo en cuenta que las variables sean categóricas (Análisis de correspondencias simple y múltiple) o que haya una mezcla de continuas y categóricas (Análisis factorial para datos mixtos).</p>
<p>Una de las extensiones más útiles a mi modo de ver es la que permite imputar teniendo en cuenta la estructura factorial y también que las observaciones estén asociadas, por ejemplo que tenga una clasificación previa, vía segmentación o un cluster previo.</p>
<p>Por ejemplo podría tener datos de clientes de diferentes provincias de España, unirlo todo en un conjunto de datos dónde tenga la variable que indica de qué provincia es cada cliente y poder obtener una estructura factorial global general y una estructura factorial específica para cada provincia y poder utilizar ambas estructuras para imputar los valores perdidos. Sería una parte general y una parte específica. ¿No os recuerda a los modelos mixtos bayesianos o a la estrategia de de modelo global y particular de <a href="https://www.youtube.com/watch?v=oGjcWWITxMI&amp;t=23s">Carlos</a> ?</p>
<p>Bueno, pues todo eso se puede hacer con la librería <code>missMDA</code>. Como ejemplo podemos ver el dataset <code>ozone</code></p>
<p><em>Description</em>
This dataset contains 112 daily measurements of meteorological variables (wind speed, temperature, rainfall, etc.) and ozone concentration recorded in Rennes (France) during the summer 2001. There are 11 continuous variables and 2 categorical variables with 2 or 4 levels. Some values are missing.</p>
<pre class="r"><code>data(ozone)
head(ozone,6)</code></pre>
<pre><code>##          maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v
## 20010601    87 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946     84
## 20010602    NA 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87
## 20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82
## 20010604   114 16.2 19.7 22.5   1   NA    0  0.9848      NA      NA     92
## 20010605    94 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301    114
## 20010606    80 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000     NA
##           vent pluie
## 20010601  Nord   Sec
## 20010602  Nord   Sec
## 20010603   Est  &lt;NA&gt;
## 20010604  &lt;NA&gt;   Sec
## 20010605 Ouest   Sec
## 20010606 Ouest Pluie</code></pre>
<p>Y vamos a usar como variable de grupo <code>vent</code> y vemos que tenemos por ejemplo paara la segunda fila valores perdidos en la variable numérica <code>maxO3</code> o para la tercer fila tenemos un valor perdido para la variable categórica <code>pluie</code></p>
<pre class="r"><code>ozone[c(&#39;20010602&#39;,&#39;20010603&#39;), ]</code></pre>
<pre><code>##          maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15 maxO3v vent
## 20010602    NA 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000     87 Nord
## 20010603    92 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209     82  Est
##          pluie
## 20010602   Sec
## 20010603  &lt;NA&gt;</code></pre>
<p>Para aplicar el método de imputación tenemos que decidir qué número de componentes queremos para la estructura general y cuántos para la particular.</p>
<pre class="r"><code># en ifac tenemos que poner el índice de la variable de grupo (de tipo factor), vent es la 12
ncp_estim &lt;- estim_ncpMultilevel(ozone, ifac = 12)</code></pre>
<p>Y nos devuelve el número de componentes estimados entre los grupos <code>ncpB</code> y el número de componentes estimados dentro de los grupos.</p>
<pre class="r"><code>ncp_estim$ncpB</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>ncp_estim$ncpW</code></pre>
<pre><code>## [1] 3</code></pre>
<p>Y con esto se lo pasamos a la función <code>imputeMultilevel</code> y hacemos la imputación</p>
<pre class="r"><code>ozone_multilevel_imp &lt;-  imputeMultilevel(ozone, ifac = 12, ncpB = 1, ncpW= 3)</code></pre>
<pre><code>## Warning in imputeMultilevel(ozone, ifac = 12, ncpB = 1, ncpW = 3): Rows with
## missing valued on the group variables are dropped</code></pre>
<p>Y podemos ver la imputación que ha realizado</p>
<pre class="r"><code>head(ozone_multilevel_imp$completeObs)</code></pre>
<pre><code>##             maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15
## 20010601 87.00000 15.6 18.5 18.4   4    4    8  0.6946 -1.7101 -0.6946
## 20010602 79.51042 17.0 18.4 17.7   5    5    7 -4.3301 -4.0000 -3.0000
## 20010603 92.00000 15.3 17.6 19.5   2    5    4  2.9544  1.8794  0.5209
## 20010605 94.00000 17.4 20.5 20.4   8    8    7 -0.5000 -2.9544 -4.3301
## 20010606 80.00000 17.7 19.8 18.3   6    6    7 -5.6382 -5.0000 -6.0000
## 20010607 68.07716 16.8 15.6 14.9   7    8    8 -4.3301 -1.8794 -3.7588
##             maxO3v  vent pluie
## 20010601  84.00000  Nord   Sec
## 20010602  87.00000  Nord   Sec
## 20010603  82.00000   Est   Sec
## 20010605 114.00000 Ouest   Sec
## 20010606  75.52026 Ouest Pluie
## 20010607  80.00000 Ouest   Sec</code></pre>
<p>Y vemos que ha realizado tanto imputación de la variable numérica <code>maxO3</code> para el dato de 20010602, como imputación de la variable categórica <code>pluie</code> para el datos de 20010603</p>
<pre class="r"><code>ozone_multilevel_imp$completeObs[c(&#39;20010602&#39;,&#39;20010603&#39;), c(&quot;maxO3&quot;, &quot;pluie&quot;) ]</code></pre>
<pre><code>##             maxO3 pluie
## 20010602 79.51042   Sec
## 20010603 92.00000   Sec</code></pre>
<p>Lo dicho, me parece una técnica interesante cuándo se tiene por ejemplo una variable que te clasifica los clientes (ya sea una clasificación previa o dada por negocio) y tenemos datos faltantes tanto para variables numéricas como categóricas. Me parece una mejor solución que imputar por la media, mediana o simplemente asignar un valor pseudo aleatorio tipo -9999. Además de que el enfoque geométrico-algebraico de las técnicas de componentes principales siempre me ha gustado.</p>
<p>Y como decía al principio <em>Quien renuncia a la estructura, deja dinero encima de la mesa.</em></p>
<p>Feliz semana.</p>
</div>
