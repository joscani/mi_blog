---
title: ÑAAS
author: jlcr
date: '2019-02-06'
slug: ñaas
categories:
  - spark
tags: []
description: ''
topics: []
---



<p>Por motivos que no vienen al caso un compañero del curro necesita hacer en spark una regresión lineal para los datos de cada cliente y extraer el coeficiente de una variable.
Así que vamos a hacer algo que denomino ÑASS (Ñapas As A Service)</p>
<div id="como-lo-hariamos-en-r" class="section level2">
<h2>Cómo lo haríamos en R</h2>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.1.0       ✔ purrr   0.3.2  
## ✔ tibble  2.1.1       ✔ dplyr   0.8.0.1
## ✔ tidyr   0.8.3       ✔ stringr 1.4.0  
## ✔ readr   1.3.1       ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code># simulto datos
x &lt;- rnorm(100, 2, 10)
y &lt;- 2 + 3 * x + rnorm(length(x), 1, 3)
df &lt;- data.frame(id = rep(1:100, each = 3),
                 y = y ,
                 x = x)</code></pre>
<p>Hacemos un <code>group_by</code> y un <code>do</code>, ya sé que en R haríamos un <code>lm(y ~ factor(id) * x, data =df  )</code> y punto, pero es por algo lo de hacerlo de otra forma.</p>
<pre class="r"><code>coeficientes &lt;- df %&gt;%
  group_by(id) %&gt;%
  do(coef_x = coef(lm(y ~ x, .))[2]) %&gt;%
  unnest(coef_x)</code></pre>
<pre class="r"><code>coeficientes</code></pre>
<pre><code>## # A tibble: 100 x 2
##       id coef_x
##    &lt;int&gt;  &lt;dbl&gt;
##  1     1   3.15
##  2     2   2.78
##  3     3   2.85
##  4     4   3.04
##  5     5   3.18
##  6     6   2.45
##  7     7   2.99
##  8     8   7.13
##  9     9   3.75
## 10    10   3.06
## # … with 90 more rows</code></pre>
</div>
<div id="en-spark" class="section level2">
<h2>En Spark</h2>
<p>Iniciamos sparklyr y creamos el spark dataframe a partir de df</p>
<pre class="r"><code>library(sparklyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;sparklyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     invoke</code></pre>
<pre class="r"><code>sc &lt;- spark_connect(master = &quot;local&quot;)</code></pre>
<pre class="r"><code>df_tbl &lt;- sc %&gt;% sdf_copy_to(df, name = &quot;df_spark&quot;, overwrite = TRUE)
df_tbl</code></pre>
<pre><code>## # Source: spark&lt;df_spark&gt; [?? x 3]
##       id      y      x
##    &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1     1 -18.9   -8.24
##  2     1  27.4    6.79
##  3     1 -28.4  -10.7 
##  4     2  37.4   10.4 
##  5     2  -6.58  -3.45
##  6     2  24.6    9.95
##  7     3  23.4    6.32
##  8     3 -49.5  -17.1 
##  9     3  18.7    8.48
## 10     4  21.1    6.48
## # … with more rows</code></pre>
<p>Y usamos ahora casi la misma sintaxis que antes, pero en vez de usar <code>lm</code> usamos <code>ml_linear_regression</code> de MLlib.</p>
<pre class="r"><code>coeficientes_spark &lt;-  df_tbl %&gt;% group_by(id) %&gt;% 
  do(coeficientes = coef(ml_linear_regression(., y ~ x))[[2]])  %&gt;% 
  unnest(coeficientes)

coeficientes_spark</code></pre>
<pre><code>## # A tibble: 100 x 2
##       id coeficientes
##    &lt;int&gt;        &lt;dbl&gt;
##  1    12         2.83
##  2    13         3.20
##  3    14         2.65
##  4    18         3.00
##  5    25         3.08
##  6    37         2.71
##  7    38         3.09
##  8    46         2.76
##  9    50         3.22
## 10    52         2.64
## # … with 90 more rows</code></pre>
<p>Y lo llamo “ÑAAS” porque aunque es verdad que me hace los modelos en <strong>spark</strong> para cada <code>id</code> el resultado de aplicar coef al modelo me devuelve el coeficiente pero en estructura de datos de R, no en spark y lo que queremos es que los coeficientes estén en otro sparkdataframes. Así que si alguien sabe como hacer esto en <em>scala</em> usando UDF’s o UDAF’s que lo comente por aquí.</p>
</div>
