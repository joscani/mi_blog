---
title: ÑAAS
author: jlcr
date: '2019-02-06'
slug: ñaas
categories:
  - spark
tags: []
description: ''
topics: []
---



<p>Por motivos que no vienen al caso un compañero del curro necesita hacer en spark una regresión lineal para los datos de cada cliente y extraer el coeficiente de una variable.
Así que vamos a hacer algo que denomino ÑASS (Ñapas As A Service)</p>
<div id="como-lo-hariamos-en-r" class="section level2">
<h2>Cómo lo haríamos en R</h2>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.1.0     ✔ purrr   0.3.0
## ✔ tibble  2.0.1     ✔ dplyr   0.7.8
## ✔ tidyr   0.8.2     ✔ stringr 1.3.1
## ✔ readr   1.3.1     ✔ forcats 0.3.0</code></pre>
<pre><code>## ── Conflicts ───────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code># simulto datos
x &lt;- rnorm(100, 2, 10)
y &lt;- 2 + 3 * x + rnorm(length(x), 1, 3)
df &lt;- data.frame(id = rep(1:100, each = 3),
                 y = y ,
                 x = x)</code></pre>
<p>Hacemos un <code>group_by</code> y un <code>do</code>, ya sé que en R haríamos un <code>lm(y ~ factor(id) * x, data =df  )</code> y punto, pero es por algo lo de hacerlo de otra forma.</p>
<pre class="r"><code>coeficientes &lt;- df %&gt;%
  group_by(id) %&gt;%
  do(coef_x = coef(lm(y ~ x, .))[2]) %&gt;%
  unnest(coef_x)</code></pre>
<pre class="r"><code>coeficientes</code></pre>
<pre><code>## # A tibble: 100 x 2
##       id coef_x
##    &lt;int&gt;  &lt;dbl&gt;
##  1     1   3.73
##  2     2   2.00
##  3     3   3.08
##  4     4   2.56
##  5     5   2.92
##  6     6   2.75
##  7     7   3.26
##  8     8   2.74
##  9     9   2.97
## 10    10   3.11
## # … with 90 more rows</code></pre>
</div>
<div id="en-spark" class="section level2">
<h2>En Spark</h2>
<p>Iniciamos sparklyr y creamos el spark dataframe a partir de df</p>
<pre class="r"><code>library(sparklyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;sparklyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     invoke</code></pre>
<pre class="r"><code>sc &lt;- spark_connect(master = &quot;local&quot;)</code></pre>
<pre class="r"><code>df_tbl &lt;- sc %&gt;% sdf_copy_to(df, name = &quot;df_spark&quot;, overwrite = TRUE)
df_tbl</code></pre>
<pre><code>## # Source: spark&lt;df_spark&gt; [?? x 3]
##       id      y        x
##    &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;
##  1     1   8.95   2.35  
##  2     1  12.5    2.14  
##  3     1  21.4    5.03  
##  4     2  33.3   11.1   
##  5     2  40.8   11.1   
##  6     2  27.3    6.28  
##  7     3  -6.29  -2.95  
##  8     3   1.98   0.0571
##  9     3 -15.8   -5.70  
## 10     4 -11.3   -6.87  
## # … with more rows</code></pre>
<p>Y usamos ahora casi la misma sintaxis que antes, pero en vez de usar <code>lm</code> usamos <code>ml_linear_regression</code> de MLlib.</p>
<pre class="r"><code>coeficientes_spark &lt;-  df_tbl %&gt;% group_by(id) %&gt;% 
  do(coeficientes = coef(ml_linear_regression(., y ~ x))[[2]])  %&gt;% 
  unnest(coeficientes)

coeficientes_spark</code></pre>
<pre><code>## # A tibble: 100 x 2
##       id coeficientes
##    &lt;int&gt;        &lt;dbl&gt;
##  1    12         3.04
##  2    13         3.53
##  3    14         2.90
##  4    18         2.39
##  5    25         2.84
##  6    37         2.64
##  7    38         2.96
##  8    46         3.47
##  9    50         2.98
## 10    52         2.85
## # … with 90 more rows</code></pre>
<p>Y lo llamo “ÑAAS” porque aunque es verdad que me hace los modelos en <strong>spark</strong> para cada <code>id</code> el resultado de aplicar coef al modelo me devuelve el coeficiente pero en estructura de datos de R, no en spark y lo que queremos es que los coeficientes estén en otro sparkdataframes. Así que si alguien sabe como hacer esto en <em>scala</em> usando UDF’s o UDAF’s que lo comente por aquí.</p>
</div>
