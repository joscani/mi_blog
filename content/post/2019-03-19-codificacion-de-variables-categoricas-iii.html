---
title: Codificación de variables categóricas III
author: jlcr
date: '2019-03-19'
categories:
  - estadística
tags:
  - estadística
slug: codificacion-de-variables-categoricas-iii
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<script src="/rmarkdown-libs/viz/viz.js"></script>
<link href="/rmarkdown-libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="/rmarkdown-libs/grViz-binding/grViz.js"></script>


<p>Hoy vamos a comparar dos formas de codificar variables categóricas basadas en <strong>reducción de dimensionalidad</strong>, a saber, embeddings con redes neuronales frente a Análisis de Correspondencias.</p>
<p>Para eso vamos a utilizar unos datos de kaggle de hace 2 años, se trata de un dataset donde se recoge el número de bicicletas que cruzan a diario los principales puentes de NY, <a href="https://www.kaggle.com/new-york-city/nyc-east-river-bicycle-crossings">datos</a></p>
<p>La idea es hacer un modelo muy simple para predecir el número de ciclistas que cruzan a diario por “Manhattan.Bridge” usando como variable explicativa el día de la semana.
El día de la semana lo codificaremos de 3 formas distintas.</p>
<ul>
<li>Codificación parcial (One hot encoder)</li>
<li>Codificación con embeddings en 3 dimensiones</li>
<li>Codificación usando análisis de correspondencias con 3 dimensiones</li>
</ul>
<p>Para la codificación con embeddings y el análisis de correspondencias utilizaremos la relación que hay entre el número de ciclistas que cruzan el puente de Brooklyn y el día de la semana.</p>
<div id="datos" class="section level2">
<h2>Datos</h2>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ──────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.1.0       ✔ purrr   0.3.2  
## ✔ tibble  2.1.1       ✔ dplyr   0.8.0.1
## ✔ tidyr   0.8.3       ✔ stringr 1.4.0  
## ✔ readr   1.3.1       ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>df &lt;- read.csv(&quot;../../data/nyc-east-river-bicycle-counts.csv&quot;)
df &lt;- df[,-1]

df &lt;- df[, c(&quot;Date&quot;, &quot;Brooklyn.Bridge&quot;, &quot;Manhattan.Bridge&quot;)]

df &lt;- unique(df)

df$date &lt;- as.Date(df$Date)
df$weekday &lt;- lubridate::wday(df$date)

DT::datatable(df)</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30"],["2016-04-01 00:00:00","2016-04-02 00:00:00","2016-04-03 00:00:00","2016-04-04 00:00:00","2016-04-05 00:00:00","2016-04-06 00:00:00","2016-04-07 00:00:00","2016-04-08 00:00:00","2016-04-09 00:00:00","2016-04-10 00:00:00","2016-04-11 00:00:00","2016-04-12 00:00:00","2016-04-13 00:00:00","2016-04-14 00:00:00","2016-04-15 00:00:00","2016-04-16 00:00:00","2016-04-17 00:00:00","2016-04-18 00:00:00","2016-04-19 00:00:00","2016-04-20 00:00:00","2016-04-21 00:00:00","2016-04-22 00:00:00","2016-04-23 00:00:00","2016-04-24 00:00:00","2016-04-25 00:00:00","2016-04-26 00:00:00","2016-04-27 00:00:00","2016-04-28 00:00:00","2016-04-29 00:00:00","2016-04-30 00:00:00"],[1704,827,526,521,1416,1885,1276,1982,504,1447,2005,1045,2840,2861,2770,2384,3147,3871,3501,3450,3436,2975,2055,2798,3463,1997,3343,2486,2375,3199],[3126,1646,1232,1067,2617,3329,2581,3455,997,2387,3791,2178,5395,5309,5072,4316,4969,6823,6951,6574,6452,4907,3276,4650,5978,3520,5606,4152,4178,4952],["2016-04-01","2016-04-02","2016-04-03","2016-04-04","2016-04-05","2016-04-06","2016-04-07","2016-04-08","2016-04-09","2016-04-10","2016-04-11","2016-04-12","2016-04-13","2016-04-14","2016-04-15","2016-04-16","2016-04-17","2016-04-18","2016-04-19","2016-04-20","2016-04-21","2016-04-22","2016-04-23","2016-04-24","2016-04-25","2016-04-26","2016-04-27","2016-04-28","2016-04-29","2016-04-30"],[6,7,1,2,3,4,5,6,7,1,2,3,4,5,6,7,1,2,3,4,5,6,7,1,2,3,4,5,6,7]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Date<\/th>\n      <th>Brooklyn.Bridge<\/th>\n      <th>Manhattan.Bridge<\/th>\n      <th>date<\/th>\n      <th>weekday<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,5]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="codificacion-con-embeddings" class="section level2">
<h2>Codificación con embeddings</h2>
<p>Creamos la variable <code>Scaledusers</code> como la variable estandarizada del número de ciclistas que cruzan el puente de Brooklyn</p>
<pre class="r"><code>df$users &lt;- df$Brooklyn.Bridge

df &lt;- df[df$users &gt; 0, ]
df &lt;- df[!is.na(df$users), ]
df &lt;- df[!is.na(df$weekday), ]

df$ScaledUsers &lt;- scale(df$users)</code></pre>
<p>Queremos hacer un embeddings de la variable día de la semana, para eso vamos a utilizar <a href="https://keras.rstudio.com/"><strong>keras</strong></a></p>
<pre class="r"><code># indico que voy a usar el entorno de python y tensorflow donde tengo instalado keras
Sys.setenv(RETICULATE_PYTHON = &quot;/home/jose/.virtualenvs/r-tensorflow/bin/python&quot;)

library(keras)

# capa de entrada
inp1 &lt;- layer_input(shape = c(1), name = &#39;inp_weekday&#39;)

# capa de embeding donde reducimos a dimensión 3
embedding_out1 &lt;-
    inp1 %&gt;% layer_embedding(
        input_dim = 7 + 1, #  7 dias mas bias
        output_dim = 3, # queremos 3 dimensiones embedding
        input_length = 1,
        name = &quot;embedding_weekday&quot;
    ) %&gt;%  layer_flatten()

# inicio modelo combinado
modelo_combinado &lt;- keras_model_sequential()

# arquitectura:
# capa de embedding  + una capa densa de 20 neuronas 
modelo_combinado &lt;- embedding_out1 %&gt;%
    layer_dense(units = 20, activation = &quot;relu&quot;) %&gt;%
    layer_dense(units = 1)

# juntamos capa de entrada más las capas que tienen  el embedding, y las densas
model &lt;- keras::keras_model(inputs = inp1, outputs = modelo_combinado)</code></pre>
<p>Tenenos un modelo con 125 parámetros, ¿realmente tiene sentido esto?</p>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #     
## ===========================================================================
## inp_weekday (InputLayer)         (None, 1)                     0           
## ___________________________________________________________________________
## embedding_weekday (Embedding)    (None, 1, 3)                  24          
## ___________________________________________________________________________
## flatten_1 (Flatten)              (None, 3)                     0           
## ___________________________________________________________________________
## dense_1 (Dense)                  (None, 20)                    80          
## ___________________________________________________________________________
## dense_2 (Dense)                  (None, 1)                     21          
## ===========================================================================
## Total params: 125
## Trainable params: 125
## Non-trainable params: 0
## ___________________________________________________________________________</code></pre>
<pre class="r"><code>model %&gt;% 
  deepviz::plot_model()</code></pre>
<div id="htmlwidget-2" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"diagram":"digraph {\n\ngraph [layout = \"neato\",\n       outputorder = \"edgesfirst\",\n       bgcolor = \"white\"]\n\nnode [fontname = \"Helvetica\",\n      fontsize = \"10\",\n      shape = \"circle\",\n      fixedsize = \"true\",\n      width = \"0.5\",\n      style = \"filled\",\n      fillcolor = \"aliceblue\",\n      color = \"gray70\",\n      fontcolor = \"gray50\"]\n\nedge [fontname = \"Helvetica\",\n     fontsize = \"8\",\n     len = \"1.5\",\n     color = \"gray80\",\n     arrowsize = \"0.5\"]\n\n  \"1\" [label = \"inp_weekday\nInputLayer\n\", shape = \"rectangle\", fixedsize = \"FALSE\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,5!\"] \n  \"2\" [label = \"embedding_weekday\nEmbedding\n\", shape = \"rectangle\", fixedsize = \"FALSE\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,4!\"] \n  \"3\" [label = \"flatten_1\nFlatten\n\", shape = \"rectangle\", fixedsize = \"FALSE\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,3!\"] \n  \"4\" [label = \"dense_1\nDense\nrelu\", shape = \"rectangle\", fixedsize = \"FALSE\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,2!\"] \n  \"5\" [label = \"dense_2\nDense\nlinear\", shape = \"rectangle\", fixedsize = \"FALSE\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,1!\"] \n  \"1\"->\"2\" \n  \"2\"->\"3\" \n  \"3\"->\"4\" \n  \"4\"->\"5\" \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>Compilamos el modelo, eligiendo que lo ajuste por gradiente descendente estocástico</p>
<pre class="r"><code>model %&gt;%
  compile(loss = &quot;mean_squared_error&quot;, optimizer = &quot;sgd&quot;, metric=&quot;accuracy&quot;) </code></pre>
<p>Ajustamos el modelo</p>
<pre class="r"><code>inputVariables &lt;- list(as.matrix(df$weekday))

hist &lt;- model %&gt;%
  fit(
    x = inputVariables,
    y = as.matrix(df$ScaledUsers),
    epochs = 70,
    batch_size = 2
  )</code></pre>
<p>Extraemos la capa de embeddings, y vemos las 3 dimensiones extraídas</p>
<pre class="r"><code>layer &lt;- get_layer(model, &quot;embedding_weekday&quot;)
embeddings_wday &lt;- data.frame(layer$get_weights()[[1]])
embeddings_wday</code></pre>
<pre><code>##             X1          X2          X3
## 1 -0.043044936 -0.03500011  0.01742882
## 2  0.114643887 -0.07663260  0.21111749
## 3 -0.107565761 -0.04164825 -0.08763187
## 4  0.105061002 -0.06102847  0.20929545
## 5 -0.117075324  0.12431101 -0.38657519
## 6 -0.119295932  0.01848904 -0.10451434
## 7 -0.002129603  0.03943805 -0.02335814
## 8  0.251920283 -0.07531382  0.28962144</code></pre>
<p>Juntamos con el dataset original</p>
<pre class="r"><code>embeddings_wday$name &lt;- c(&quot;none&quot;, levels(lubridate::wday(df$date, label = T)))

df$weekDayF &lt;- lubridate::wday(df$date, label = T)
embeddings_wday$lookup &lt;- c(&quot;none&quot;, levels(df$weekDayF))
df &lt;- df %&gt;% 
  left_join( embeddings_wday, by= c(&quot;weekDayF&quot; = &quot;lookup&quot;))</code></pre>
<pre><code>## Warning: Column `weekDayF`/`lookup` joining factor and character vector,
## coercing into character vector</code></pre>
<pre class="r"><code>df %&gt;% 
  select(weekDayF, X1, X2, X3) %&gt;%
  head()</code></pre>
<pre><code>##   weekDayF           X1          X2          X3
## 1      Fri -0.002129603  0.03943805 -0.02335814
## 2      Sat  0.251920283 -0.07531382  0.28962144
## 3      Sun  0.114643887 -0.07663260  0.21111749
## 4      Mon -0.107565761 -0.04164825 -0.08763187
## 5      Tue  0.105061002 -0.06102847  0.20929545
## 6      Wed -0.117075324  0.12431101 -0.38657519</code></pre>
<div id="codificacion-usando-analisis-de-correspondencias-simple" class="section level3">
<h3>Codificación usando análisis de correspondencias simple</h3>
<p>En el análisis de correspondencias clásico las variables han de ser categóricas, así que categorizamos el número de ciclistas que cruzan por Brooklyn en 5 niveles.</p>
<pre class="r"><code>df$brooklyn_cat &lt;- cut(df$Brooklyn.Bridge,5)
table(df$brooklyn_cat)</code></pre>
<pre><code>## 
##      (501,1.18e+03] (1.18e+03,1.85e+03] (1.85e+03,2.52e+03] 
##                   5                   4                   8 
##  (2.52e+03,3.2e+03]  (3.2e+03,3.87e+03] 
##                   6                   7</code></pre>
<p>Y ahora aplicamos el análisis de correspondencias entre las variables <code>brooklyn_cat</code> y <code>weekDayF</code></p>
<p>Nota. Utilizo la función MCA del correspondencias múltiples porque es más sencillo extraer las dimensiones.</p>
<pre class="r"><code>library(FactoMineR)
library(factoextra)</code></pre>
<pre><code>## Welcome! Related Books: `Practical Guide To Cluster Analysis in R` at https://goo.gl/13EFCZ</code></pre>
<pre class="r"><code>res_ca &lt;- MCA(df[, c(&quot;brooklyn_cat&quot;,&quot;weekDayF&quot;)], ncp = 3, graph = FALSE)

fviz_mca(res_ca)</code></pre>
<p><img src="/post/2019-03-19-codificacion-de-variables-categoricas-iii_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Extraigo las dimensiones</p>
<pre class="r"><code>coordenadas &lt;- as.data.frame(res_ca$ind$coord)
colnames(coordenadas) &lt;- paste0(&quot;MCA_&quot;,1:3)
df &lt;- cbind(df, coordenadas)


df %&gt;% 
  select_at(c(paste0(&quot;MCA_&quot;,1:3), paste0(&quot;X&quot;,1:3))) %&gt;% 
  DT::datatable(.)</code></pre>
<div id="htmlwidget-3" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30"],[1.16775619176984,-0.969741640673681,0.259460502444066,-1.08415432429758,0.35837748829935,-0.302616841090448,0.848936092533866,0.465841992788705,-0.969741640673681,1.25235358039781,-0.793175445324963,-0.634515589654396,0.579724094412422,1.0293628290556,1.34818292829158,-0.678762761701066,1.43278031691955,-1.16670877118293,-0.717070036539746,-0.676150166948414,-0.226511432305231,1.34818292829158,-0.678762761701066,1.43278031691955,-1.16670877118293,-0.343536710681781,-0.676150166948414,0.147021893552734,0.465841992788705,-1.05229608755903],[0.153860547390106,1.53639059967315,1.47795465296831,0.736185586973788,0.598912848979276,-0.969167904956931,-0.110872541124429,-0.156431365829396,1.53639059967315,0.792678464360803,-0.259382514853225,1.28418903758679,-1.09347385378794,-0.545470403174944,-0.280737314660408,0.540822497846133,0.358080602310288,-0.813710883438744,-0.265707432825745,-1.52349627354245,-0.97549282292945,-0.280737314660408,0.540822497846133,0.358080602310288,-0.813710883438744,0.288620935759774,-1.52349627354245,-0.421164454343931,-0.156431365829396,-0.0135058707393863],[-0.711997623323235,-0.0279940210586293,1.23175626104699,0.690047192382899,0.052809600761121,-0.540546759714443,-0.0186105673760249,-1.57146510754479,-0.0279940210586283,0.932049961308335,-0.469126591577309,0.352515900499774,0.541992321304533,0.204461029421397,-0.488926026525813,-1.18716780501884,1.15512155810576,0.752516045146827,0.414984753263702,0.681095877009693,0.343564585126556,-0.488926026525813,-1.18716780501884,1.15512155810576,0.752516045146827,-0.806657883460433,0.681095877009693,-0.87807805159758,-1.57146510754479,0.0344748317053],[-0.00212960341013968,0.251920282840729,0.114643886685371,-0.107565760612488,0.105061002075672,-0.117075324058533,-0.119295932352543,-0.00212960341013968,0.251920282840729,0.114643886685371,-0.107565760612488,0.105061002075672,-0.117075324058533,-0.119295932352543,-0.00212960341013968,0.251920282840729,0.114643886685371,-0.107565760612488,0.105061002075672,-0.117075324058533,-0.119295932352543,-0.00212960341013968,0.251920282840729,0.114643886685371,-0.107565760612488,0.105061002075672,-0.117075324058533,-0.119295932352543,-0.00212960341013968,0.251920282840729],[0.0394380502402782,-0.0753138214349747,-0.0766326040029526,-0.0416482500731945,-0.061028465628624,0.124311007559299,0.0184890367090702,0.0394380502402782,-0.0753138214349747,-0.0766326040029526,-0.0416482500731945,-0.061028465628624,0.124311007559299,0.0184890367090702,0.0394380502402782,-0.0753138214349747,-0.0766326040029526,-0.0416482500731945,-0.061028465628624,0.124311007559299,0.0184890367090702,0.0394380502402782,-0.0753138214349747,-0.0766326040029526,-0.0416482500731945,-0.061028465628624,0.124311007559299,0.0184890367090702,0.0394380502402782,-0.0753138214349747],[-0.0233581364154816,0.289621442556381,0.21111749112606,-0.0876318737864494,0.209295451641083,-0.386575192213058,-0.104514338076115,-0.0233581364154816,0.289621442556381,0.21111749112606,-0.0876318737864494,0.209295451641083,-0.386575192213058,-0.104514338076115,-0.0233581364154816,0.289621442556381,0.21111749112606,-0.0876318737864494,0.209295451641083,-0.386575192213058,-0.104514338076115,-0.0233581364154816,0.289621442556381,0.21111749112606,-0.0876318737864494,0.209295451641083,-0.386575192213058,-0.104514338076115,-0.0233581364154816,0.289621442556381]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>MCA_1<\/th>\n      <th>MCA_2<\/th>\n      <th>MCA_3<\/th>\n      <th>X1<\/th>\n      <th>X2<\/th>\n      <th>X3<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Veamos si están correlacionadas ambas codificaciones.</p>
<pre class="r"><code>correlaciones &lt;- cor(df[,c(paste0(&quot;X&quot;,1:3),paste0(&quot;MCA_&quot;,1:3))])

round(correlaciones, 2)</code></pre>
<pre><code>##          X1    X2    X3 MCA_1 MCA_2 MCA_3
## X1     1.00 -0.71  0.90 -0.10  0.75 -0.12
## X2    -0.71  1.00 -0.91  0.18 -0.76 -0.16
## X3     0.90 -0.91  1.00 -0.02  0.83 -0.05
## MCA_1 -0.10  0.18 -0.02  1.00  0.00  0.00
## MCA_2  0.75 -0.76  0.83  0.00  1.00  0.00
## MCA_3 -0.12 -0.16 -0.05  0.00  0.00  1.00</code></pre>
</div>
</div>
<div id="modelos" class="section level2">
<h2>Modelos</h2>
<p>Una vez que ya tenemos las dos codificaciones utilizando la relación entre el número de ciclistas que cruzan por el puente de Brooklyn y los días de la semana, veamos si alguna de esas codificaciones es útil a la hora de predecir el número de ciclistas que cruzan por el puente de Manhattan.</p>
<p>Creamos función que ajuste unos modelos lineales simples, utilizando la codificación usual, la obtenida por Embedding y la obtenida por análisis de correspondencias.</p>
<pre class="r"><code>testRun &lt;- function(x) {
    sample &lt;- caret::createDataPartition(df$weekDayF, list = FALSE, p = 0.8)
    train &lt;- df[sample,]
    test &lt;- df[-sample,]
    
    fit1 &lt;- lm(Manhattan.Bridge  ~ weekDayF, data = train) 
    fit2 &lt;- lm(Manhattan.Bridge ~ X1 + X2 + X3, data = train)
    fit3 &lt;- lm(Manhattan.Bridge ~ MCA_1  + MCA_2 + MCA_3, data = train)
    
    data.frame(
      run = x,
      Categ      = sqrt(mean((predict(fit1, test) - test$Manhattan.Bridge) ^ 2)),
      Embedding  = sqrt(mean((predict(fit2, test) - test$Manhattan.Bridge) ^ 2)),
      Corresp    = sqrt(mean((predict(fit3, test) - test$Manhattan.Bridge) ^ 2))
    )
}</code></pre>
<p>Aplicamos el proceso 200 veces y pintamos los rmse obtenidos</p>
<pre class="r"><code>test &lt;- map_df(1:200, testRun)
mm &lt;- gather(test, key = &quot;Tipo_codificacion&quot;, value = &quot;rmse&quot;, -run  )

ggplot(mm, aes(x=Tipo_codificacion, y= rmse)) + 
    geom_boxplot()</code></pre>
<p><img src="/post/2019-03-19-codificacion-de-variables-categoricas-iii_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Y parece, que al menos en este caso se imponen las <strong>técnicas clásicas</strong> sobre el “Deep Learning”</p>
</div>
